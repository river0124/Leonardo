CACHE_DIR = "/Users/hyungseoklee/Documents/Leonardo/backend/cache"
from loguru import logger
import json
import FinanceDataReader as fdr
import pandas as pd
from tqdm import tqdm
import sys, os
from datetime import datetime, timedelta
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from slack_notifier import post_to_slack

# ğŸ“Œ ê°•ì„¸ ì„¹í„° íŒë‹¨ ê¸°ì¤€ ì„¤ì •
MIN_RISING_COUNT = 4  # ëŒ€ì¥ì£¼ ì¤‘ ìµœì†Œ ëª‡ ê°œ ì´ìƒ ìƒìŠ¹í•´ì•¼ ê°•ì„¸ë¡œ ê°„ì£¼í• ì§€
MIN_AVG_RETURN = 0.03  # ëŒ€ì¥ì£¼ í‰ê·  ìˆ˜ìµë¥  ê¸°ì¤€ (ì˜ˆ: 0.03 â†’ 3%)
MIN_PERIOD_DAYS = 20  # ìƒìŠ¹ ê¸°ê°„ ê¸°ì¤€ (ìµœê·¼ N ê±°ë˜ì¼)
REQUIRE_STRONG_WINNER = True  # ëŒ€ì¥ì£¼ ì¤‘ í•˜ë‚˜ë¼ë„ +5% ì´ìƒ ìˆ˜ìµë¥ ì´ ìˆì–´ì•¼ í•˜ëŠ”ì§€ ì—¬ë¶€
STRONG_WINNER_THRESHOLD = 0.05  # ëŒ€ì¥ì£¼ì˜ ìˆ˜ìµë¥ ì´ ì´ ìˆ˜ì¹˜ ì´ìƒì¸ ê²ƒì´ ìˆì–´ì•¼ í•¨
MIN_RATIO_TO_HIGH52 = 0.95  # ì‹ ê³ ê°€ ëŒ€ë¹„ ìµœì†Œ ê·¼ì ‘ ë¹„ìœ¨ (ì˜ˆ: 0.98 = 98%)
MAX_RATIO_DIFF_FROM_HIGH52 = 0.5  # 52ì£¼ ì‹ ê³ ê°€ì—ì„œ ì´ ë¹„ìœ¨ ì´ìƒ ë²—ì–´ë‚œ ì¢…ëª©ì€ ì œì™¸ (ì˜ˆ: 0.10 â†’ 10%)

# Load DEBUG setting
with open(f"{CACHE_DIR}/settings.json") as f:
    settings = json.load(f)
DEBUG = settings.get("DEBUG", "False") == "True"

holidays_path = f"{CACHE_DIR}/holidays.csv"
holidays = pd.read_csv(holidays_path)
holiday_dates = set(pd.to_datetime(holidays['ë‚ ì§œ'], format="%Y%m%d").dt.date)

def remove_holidays(df):
    return df.loc[~df.index.to_series().dt.date.isin(holiday_dates)]

def find_52week_high_candidates():
    # KRX ì¢…ëª© ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    stock_list = fdr.StockListing('KRX')
    stock_list = stock_list[~stock_list['Name'].str.contains('ê´€ë¦¬|ì •ì§€|ìŠ¤íŒ©|ì „í™˜|ìš°$|ìš°[A-Z]?$|ìš°ì„ ', regex=True, na=False)]
    stock_list['Close'] = pd.to_numeric(stock_list['Close'], errors='coerce')
    stock_list = stock_list[stock_list['Close'] > 1000]

    # 52ì£¼ ê¸°ê°„ ì„¤ì •
    end = datetime.today()
    start = end - timedelta(days=365)

    results = []

    for _, row in tqdm(stock_list.iterrows(), total=stock_list.shape[0], desc="ğŸ” 52ì£¼ ì‹ ê³ ê°€ ê²€ìƒ‰ ì¤‘"):
        code = row['Code']
        name = row['Name']

        try:
            df = remove_holidays(fdr.DataReader(code, start, end))
            if df.empty or len(df) < 10:
                continue

            current_close = df['Close'].iloc[-1]
            high_52week = df['High'].max()

            # ğŸ” í˜„ì¬ê°€ê°€ 52ì£¼ ì‹ ê³ ê°€ì˜ MIN_RATIO_TO_HIGH52 ì´ìƒì´ë©´ì„œ MAX_RATIO_DIFF_FROM_HIGH52 ì´ë‚´ì¸ ê²½ìš°ë§Œ í¬í•¨
            ratio = current_close / high_52week
            if MIN_RATIO_TO_HIGH52 <= ratio and ratio >= (1 - MAX_RATIO_DIFF_FROM_HIGH52):
                results.append({
                    'Code': code,
                    'Name': name,
                    'CurrentPrice': current_close,
                    'High52Week': high_52week,
                    'Ratio': round(ratio * 100, 2)
                })

        except Exception as e:
            if DEBUG: logger.error(f"[{code}] {name}: Error -> {e}")

    df_result = pd.DataFrame(results)
    if not df_result.empty:
        df_result = df_result.sort_values(by='Ratio', ascending=False)
    return df_result


# âœ… ì„¹í„°ë³„ ëŒ€ì¥ì£¼ 5ê°œ ì¤‘ ìµœê·¼ 5ì¼ ê°„ ìƒìŠ¹ ì¢…ëª©ì´ 3ê°œ ì´ìƒì¸ ì„¹í„°ë§Œ í•„í„°ë§

import os

stock_list_path = f"{CACHE_DIR}/stock_list.csv"

# ìŠ¤í†¡ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
df_stock_info = pd.read_csv(stock_list_path)
df_stock_info = df_stock_info.dropna(subset=['MarketCap', 'Sector'])

# ì„¹í„°ë³„ ëŒ€ì¥ì£¼ 5ê°œ ì¶”ì¶œ (ì‹œê°€ì´ì•¡ ê¸°ì¤€ ìƒìœ„)
top_leaders_by_sector = (
    df_stock_info
    .sort_values(by="MarketCap", ascending=False)
    .groupby("Sector")
    .head(5)
)

# ê°•ì„¸ ì„¹í„° íŒë‹¨ì„ ìœ„í•œ ì¤€ë¹„
sector_returns = {}

# ìµœê·¼ 6ì¼ì¹˜ ë°ì´í„° (ë‹¹ì¼ í¬í•¨ 5ê±°ë˜ì¼)
# ëŒ€í‘œ ì¢…ëª©ìœ¼ë¡œë¶€í„° ê°€ì¥ ìµœê·¼ ê±°ë˜ì¼ êµ¬í•˜ê¸°
ref_df = fdr.DataReader("005930", "2024-01-01")
ref_df = remove_holidays(ref_df)
end_date = ref_df.index[-1].date()
start_date = end_date - timedelta(days=MIN_PERIOD_DAYS * 2)  # ì£¼ë§ê³¼ ê³µíœ´ì¼ í¬í•¨ ì—¬ìœ  í™•ë³´

# ëŒ€ì¥ì£¼ë“¤ì˜ ìƒìŠ¹ ì—¬ë¶€ ë° ìˆ˜ìµë¥  í™•ì¸
for _, row in tqdm(top_leaders_by_sector.iterrows(), total=top_leaders_by_sector.shape[0],
                   desc="ğŸ“Š ëŒ€ì¥ì£¼ ìƒìŠ¹ ì²´í¬", ncols=100, dynamic_ncols=False, leave=False, position=0):
    code = str(row["Code"]).zfill(6)
    sector = row["Sector"]
    try:
        df = remove_holidays(fdr.DataReader(code, start_date, end_date.strftime('%Y-%m-%d')))
        df = df.tail(MIN_PERIOD_DAYS + 1)
        if len(df) < MIN_PERIOD_DAYS + 1:
            if DEBUG: logger.warning(f"[{code}] {row['Name']} â†’ ë°ì´í„° ë¶€ì¡± (len={len(df)})")
            continue

        price_start = df['Close'].iloc[0]
        price_end = df['Close'].iloc[-1]
        ret = (price_end - price_start) / price_start

        sector_returns.setdefault(sector, []).append(ret)

    except Exception as e:
        if DEBUG: logger.error(f"[{code}] {row['Name']} ì˜¤ë¥˜: {e}")

# âœ… ê°•ì„¸ ì„¹í„° ì •ì˜:
# 1) ëŒ€ì¥ì£¼ MIN_RISING_COUNTê°œ ì´ìƒ ìƒìŠ¹
# 2) í‰ê·  ìˆ˜ìµë¥  MIN_AVG_RETURN ì´ìƒ
# 3) (ì„ íƒì ) í•˜ë‚˜ ì´ìƒì˜ ëŒ€ì¥ì£¼ê°€ STRONG_WINNER_THRESHOLD ì´ìƒ ìˆ˜ìµì„ ê¸°ë¡í•œ ê²½ìš°ë§Œ ì¸ì • (REQUIRE_STRONG_WINNER=Trueì¼ ë•Œ)
strong_sectors = [
    sector for sector, returns in sector_returns.items()
    if sum(r > 0 for r in returns) >= MIN_RISING_COUNT
       and sum(returns) / len(returns) >= MIN_AVG_RETURN
       and (not REQUIRE_STRONG_WINNER or any(r >= STRONG_WINNER_THRESHOLD for r in returns))
]

# ğŸ”¥ ìƒìŠ¹ ì¤‘ì¸ ê°•ì„¸ ì„¹í„° ëª©ë¡ ë¡œê¹…
if DEBUG:
    logger.info(f"ğŸ”¥ ìƒìŠ¹ ì¤‘ì¸ ê°•ì„¸ ì„¹í„° ëª©ë¡: {strong_sectors}")

def merge_sector_info(df_result, df_stock_info):
    df_result['Code'] = df_result['Code'].astype(str).str.zfill(6)
    df_stock_info['Code'] = df_stock_info['Code'].astype(str).str.zfill(6)
    return df_result.merge(df_stock_info[['Code', 'Sector']], on='Code', how='left')

def filter_by_strong_sector(df_result, strong_sectors):
    return df_result[df_result['Sector'].isin(strong_sectors)]

def filter_small_caps(df_result, df_stock_info):
    df_result = df_result.merge(df_stock_info[['Code', 'Market', 'MarketCap']], on='Code', how='left')
    df_result = df_result[
        ((df_result['Market'] == 'KOSPI') & (df_result['MarketCap'] >= 500000000000)) |
        ((df_result['Market'] == 'KOSDAQ') & (df_result['MarketCap'] >= 300000000000))
    ]
    return df_result

if __name__ == "__main__":
    df_result = find_52week_high_candidates()
    df_result = merge_sector_info(df_result, df_stock_info)

    # ğŸš« ê°•ì„¸ ì„¹í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not strong_sectors:
        if DEBUG: logger.info("âš ï¸ ê°•ì„¸ ì„¹í„°ê°€ ì—†ì–´ ì¶”ì²œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        post_to_slack("âš ï¸ ê°•ì„¸ ì„¹í„°ê°€ ì—†ì–´ ì¶”ì²œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit()

    df_result = filter_by_strong_sector(df_result, strong_sectors)
    df_result = filter_small_caps(df_result, df_stock_info)

    # âœ… ìµœì¢… ê²°ê³¼ ì €ì¥
    output_path = f"{CACHE_DIR}/high52.json"
    df_result = df_result.drop(columns=['MarketCap'], errors='ignore')
    df_result.to_json(output_path, orient='records', force_ascii=False, indent=2)
    if DEBUG: logger.success(f"ğŸ“Š ê°•ì„¸ ì„¹í„° ë‚´ ì¶”ì²œ ì¢…ëª© ìˆ˜: {len(df_result)}ê°œ")
    post_to_slack(f"âœ… ê°•ì„¸ ì„¹í„° ë‚´ ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\nì´ ì¢…ëª© ìˆ˜: {len(df_result)}ê°œ")